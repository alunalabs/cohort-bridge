# Configuration for tokenized (pre-processed) data
# Use this when data has been pre-tokenized using the tokenize command

database:
  type: csv
  filename: out/tokenized_data.csv  # Path to tokenized data file
  is_tokenized: true
  # Encryption will be inferred from presence of encryption_key or encryption_key_file
  encryption_key_file: "out/tokenized_data.key"  # Key file for encrypted tokenized data

# Network configuration for peer-to-peer matching
peer:
  host: 127.0.0.1
  port: 8081

listen_port: 8082

# Security configuration
security:
  rate_limit_per_min: 5

# Timeout configuration
timeouts:
  connection_timeout: 30s
  read_timeout: 60s
  write_timeout: 60s
  idle_timeout: 300s
  handshake_timeout: 30s

# Logging configuration
logging:
  level: "info"
  file: "logs/tokenized_matching.log"
  max_size: 100
  max_backups: 3
  max_age: 30

# Matching parameters for tokenized data
matching:
  hamming_threshold: 20
  jaccard_threshold: 0.7

# Note: Tokenized data mode provides enhanced security by separating
# the tokenization process from the matching process 